<head>
    <style>
      .b {
        background-color: #BBDEFB;
        padding: 10px 20px;
      }
    </style>
</head>


<div class="row g-5 mb-5">
  <div>
    <h3 class="fw-bold border-bottom pb-3 mb-5">Main Projects</h3>
    {% if page.title == "Home" %}
      includes publications.html home
    
      <h4 class="b" id="u2net_portrait_sketch"><A href = "https://github.com/HyeongminMoon/U-2-Net_portrait_sketch">(2021) Portrait sketch by improving segmentation model</A></h4>
  </div>
</div>

<div class="row g-5 mb-5">
  <div class="col-md-6"> 
      <br></br>
      <br></br>
      <h5> High-detailed Segmentation becomes Portrait sketch </h5>
      <p> - The U-2Net is famous for segmetation model.</p>
      <p> - It's model has a complex structure so it does segmetnation to the level that presents a strand of hair.</p>
      <h5> Enhancing to become portrait model </h5>
      <p> - Based on this high quality, people thought that it is possible to use this model for portrait sketch but at first it had not good performance. </p>
      <p> - I tried various trying to enhance this model such as preprocessing images, devising a dedicated augmentation techniques. </p>
      <p> - If you want to get information about U2Net, please refer <a href="https://github.com/xuebinqin/U-2-Net">this original repository</a> <p>
  </div>
  <div class="col-md-6">
    
<p><br><img src="https://user-images.githubusercontent.com/32811724/143386093-f9f3b1e0-4e8b-4fcd-9303-56a872888f5d.png" width="45%"></img>
<img src="https://user-images.githubusercontent.com/32811724/143386103-8eb3fb3b-8bed-4f37-8a49-3b4ef1718fe4.png" width="45%"></img>
</br>
<br><img src="https://user-images.githubusercontent.com/32811724/143386178-d2eeb72e-2a33-43c8-b0f8-713efbf30709.png" width="45%"></img>
<img src="https://user-images.githubusercontent.com/32811724/143386194-614bfe30-e025-47b7-a899-43839344c172.png" width="45%"></img>
</br>
<br><img src="https://user-images.githubusercontent.com/32811724/143386187-71006f1b-9e29-4158-b01b-f4541ad057f4.png" width="45%"></img>
<img src="https://user-images.githubusercontent.com/32811724/143386196-e7215ff1-7b2c-4e9c-8554-4bd8c94fc3ff.png" width="45%"></img>
</br></p>
  </div>
</div>

<div class="row g-5 mb-5">
  <div class="col-md-6">
<p><img src="https://user-images.githubusercontent.com/32811724/143388489-1d9e0756-58e9-4ab6-98f9-ca0f0c044869.gif" alt="IU_Coin_train_custom_erode2 (1)" width="90%">
<img src="https://user-images.githubusercontent.com/32811724/143388497-3237d2db-3b80-4309-97f3-a4d7aae28321.gif" alt="Traffic_light_custom_b2" width="90%"></p>
  </div>    
  <div class="col-md-6">
      <br></br>
      <br></br>
      <h5> Video demo & TODO </h5>
      <p> - It has been confirmed that we can produce videos of a different style from conventional common black-and-white or sketch transformations.</p>
      <p> - The above one is similar to common sketch transformation but below one bring us new style, with removed dirty information.</p>
      <p> - However, additional work seems to be needed to apply the video, such as the contrast of the screen changing naturally.</p>
      <h5 id="other-things">More</h5>
      <p> - If you want to see the enhancing processes, plese refer this repository </p>
      <p> - <A href = "https://github.com/HyeongminMoon/U-2-Net_portrait_sketch">(2021) Portrait sketch by improving segmentation model</A> </p>
  </div>
</div>
    

<h4 class="b" id="edge computing">(2021) Edge computing without CUDA, with quantization & tensorflow js</h4>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/deeplab"></script>

<div class="row g-5 mb-5">
    <div class="col-md-6">
        <img id="img" src="./assets/img/demo1.jpg" alt="" width="90%"/>
        <input type="button" id="button1" onclick="predict();" value="demo"/>
        <form method="post" enctype="multipart/form-data">
        <input type="file" id="button2" onchange="changeimg(this);" accpet="image/*" value="upload image"/>
        </form>
    </div>
    <div class="col-md-6">
        <canvas id="person">
        </canvas>
    </div>
</div>
<h5> This is how to use GPU without environment setting </h5>
<p> - It is widely known that the operation speed is much faster if the deeplearning operations calculated in the gpu rather than cpu.</p>
<p> - To use GPU we need CUDA/CuDNN setting but clients don't know how to install those and don't need to know.</p>
<p> - In this situation, there is a good solution that use GPU without CUDA, is graphical backend such as WebGL. </p>
<p> - Now what we all need is preparing custom model, being lighten(using quantization) model, load model!</p>
<p> - Above demo don't need server side operation, it uses your computer resource, CPU and GPU. (So you can feel your computer get lag when you start demo)</p>
<p> - Unfortunately, there is a chache problem with processing the gpu now, so if your gpu capacity is small, it can be shutdown when executing the demo. So now, it is only allowed to work with cpu.

<script>
function changeimg(input) {
    var file = input.files[0];
    document.getElementById("img").src = URL.createObjectURL(file);
    predict();
}
    
const loadModel = async () => {
  const modelName = 'ade20k';   // set to your preferred model, either `pascal`, `cityscapes` or `ade20k`
  const quantizationBytes = 2;  // either 1, 2 or 4
  return await deeplab.load({base: modelName, quantizationBytes});
};
    
const translateSegmentationMap = async (segmentationMap) => {
  return await deeplab.toSegmentationImage(
      deeplab.getColormap(model), deeplab.getLabels(model), segmentationMap)
};

const img = document.getElementById('img');
// var pixels = tf.browser.fromPixels(img);
// pixels = tf.image.resizeBilinear(pixels, [227, 500]);//227, 500, 3
// console.log(pixels)
// const input = tf.zeros([227, 500, 3]);
// ...
    
const predict = async () => {
    
    const model = await loadModel();

    const output = await model.segment(img).then((output) =>{
//         console.timeEnd("predict time");
        const {legend, height, width, segmentationMap} = output
//         console.log(`The predicted classes are ${JSON.stringify(legend)}`);
        //             console.log(segmentationMap);
        var canvas = document.getElementById('person');
            canvas.style.width = '90%';
            canvas.style.height = '90%';
        canvas.width = width;
        canvas.height = height;
//         console.log(width, height)
        ctx = canvas.getContext('2d');
        var imgdata = new ImageData(segmentationMap, width, height);
        ctx.putImageData(imgdata, 0, 0);
    });

};

// predict();
</script>


<h4 class="b" id="frcnn"><A href = "https://github.com/HyeongminMoon/FRCNN_trademark_similarity">(2021) Rank search by image similarity and multi label classificaion </A></h4>


<h5> Multi label classification </h5>
<p> - One of the difficult trademark's feature is figurative. It could be expressed like "the heart shaping cat", "the S shaping chicken", 
    etc. </p>
<p> - And trademarks are classificated by ViennaCodes, but It couldn't explain the all image appearance.</p>
<p> - So we need to make new classification table based on ViennaCodes.</p>
<p> - We tried to contain the all feature but some are removed due to accuracy. </p>
<p> - For example, the trademarks' viennacodes distribution is not flat because many trademark contain a Creature.</p>
<img src="./assets/img/dist.png" width="90%"></img>

<h6> result samples </h6>
<p><br><img src="./assets/img/det1.jpg" width="30%" title="det1" alt="det1"></img>
<img src="./assets/img/det2.jpg" width="30%" title="det2" alt="det2"></img>
<img src="./assets/img/det3.jpg" width="30%" title="det3" alt="det3"></img><br/></p>

<div class="row g-5 mb-5">
    <div class="col-md-6">
        <br> </br>
        <h5> Cosine Similarity </h5>
        <p> - We transfer learned pretrained model efficientnet-b0 with triplet loss. </p>
        <p> - To attach triplet loss, we made triple pair dataset by above ViennaCode based trademark classification rules, 
            select two **Similar** images which has same label and one **Different** images which is selected randomly </p>
        <p> - And we calculated the Cosine Similarity from it's final fully connected vectors.</p>
        <br> </br>
        <h5> Image Similarity </h5>
        <p> - And again we mixed the results with above multi label classification score. </p>
        <p> - Finally we got final Image Similarity score </p>
    </div>
    <div class="col-md-6">
        
    </div>
</div>


<p> - Now what we all need is preparing custom model, being lighten(using quantization) model, load model!</p>
<p> - Above demo don't need server side operation, it uses your computer resource, CPU and GPU. (So you can feel your computer get lag when you start demo)</p>
<p> - Unfortunately, there is a chache problem with processing the gpu now, so if your gpu capacity is small, it can be shutdown when executing the demo. So now, it is only allowed to work with cpu.

    

<hr width = "90%" color = "black">
<h5> Project Links </h5>
      {% for item in site.data.publications.featured %}
        <p><a href="{{ item.url }}">{{ item.name }}</a></p>
      {% endfor %}
    {% else %}
      includes publications.html
      {% for item in site.data.publications.index %}
        <p><a href="{{ item.url }}">{{ item.name }}</a></p>
      {% endfor %}
    {% endif %}
